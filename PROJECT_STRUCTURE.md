# Project Structure

Complete directory structure of the enhanced Transcript Studio AI system.

```
transcript-studio-ai/
â”‚
â”œâ”€â”€ ðŸ“„ QUICKSTART.md                      # 10-minute setup guide
â”œâ”€â”€ ðŸ“„ ENHANCED_ACCURACY_GUIDE.md         # Technical deep-dive (12 pages)
â”œâ”€â”€ ðŸ“„ IMPLEMENTATION_SUMMARY.md          # Implementation overview
â”œâ”€â”€ ðŸ“„ PROJECT_STRUCTURE.md               # This file
â”‚
â”œâ”€â”€ ðŸ”§ setup.sh                           # Linux/Mac setup script
â”œâ”€â”€ ðŸ”§ setup.bat                          # Windows setup script
â”œâ”€â”€ ðŸ”§ package.json                       # Frontend dependencies
â”œâ”€â”€ ðŸ”§ vite.config.ts                     # Vite configuration
â”œâ”€â”€ ðŸ”§ tsconfig.json                      # TypeScript configuration
â”‚
â”œâ”€â”€ ðŸŒ .env.example                       # Frontend environment template
â”œâ”€â”€ ðŸŒ .env.local                         # Frontend environment (create from .env.example)
â”‚
â”œâ”€â”€ ðŸ“ src/                               # Frontend source code
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ gemini.ts                    # Original: Gemini API integration
â”‚   â”‚   â”œâ”€â”€ feedback.ts                  # Original: Feedback collection
â”‚   â”‚   â””â”€â”€ ðŸ†• postprocessing.ts         # NEW: Backend API client (250 lines)
â”‚   â”‚       â”œâ”€â”€ enhanceTranscript()      # Enhance single audio file
â”‚   â”‚       â”œâ”€â”€ enhanceChunks()          # Enhance multiple chunks
â”‚   â”‚       â”œâ”€â”€ checkBackendHealth()     # Health check
â”‚   â”‚       â”œâ”€â”€ formatEnhancedTranscript()
â”‚   â”‚       â”œâ”€â”€ exportToSRT()            # Export to subtitle format
â”‚   â”‚       â””â”€â”€ exportToJSON()           # Export with metadata
â”‚   â”‚
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â”œâ”€â”€ audio.ts                     # Real-time audio encoding
â”‚   â”‚   â”œâ”€â”€ audioSlicer.ts               # 15-minute chunk creation
â”‚   â”‚   â””â”€â”€ file.ts                      # File conversion utilities
â”‚   â”‚
â”‚   â””â”€â”€ components/
â”‚       â”œâ”€â”€ TranscriptCard.tsx           # Display and edit transcripts
â”‚       â”œâ”€â”€ AudioVisualizer.tsx          # Waveform visualization
â”‚       â”œâ”€â”€ GlossaryManager.tsx          # Custom terminology
â”‚       â”œâ”€â”€ ShortcutManager.tsx          # Keyboard shortcuts
â”‚       â””â”€â”€ ... (other components)
â”‚
â”œâ”€â”€ ðŸ“ backend/                           # ðŸ†• NEW: Python backend
â”‚   â”‚
â”‚   â”œâ”€â”€ ðŸ“„ README.md                      # Backend documentation (8 pages)
â”‚   â”œâ”€â”€ ðŸ”§ requirements.txt               # Python dependencies (15 packages)
â”‚   â”œâ”€â”€ ðŸŒ .env.example                   # Backend environment template
â”‚   â”œâ”€â”€ ðŸŒ .env                           # Backend environment (create from .env.example)
â”‚   â”‚
â”‚   â”œâ”€â”€ ðŸ main.py                        # FastAPI server (300 lines)
â”‚   â”‚   â”œâ”€â”€ POST /enhance-transcript     # Single file enhancement
â”‚   â”‚   â”œâ”€â”€ POST /enhance-chunks         # Multi-chunk enhancement
â”‚   â”‚   â””â”€â”€ GET /                        # Health check
â”‚   â”‚
â”‚   â”œâ”€â”€ ðŸ§ª test_backend.py                # Setup verification script
â”‚   â”‚
â”‚   â””â”€â”€ ðŸ“ services/                      # Backend services
â”‚       â”‚
â”‚       â”œâ”€â”€ __init__.py                   # Services package
â”‚       â”‚
â”‚       â”œâ”€â”€ ðŸŽ™ï¸ whisperx_service.py       # WhisperX integration (200 lines)
â”‚       â”‚   â”œâ”€â”€ WhisperXService
â”‚       â”‚   â”‚   â”œâ”€â”€ transcribe_and_align()     # Force alignment
â”‚       â”‚   â”‚   â”œâ”€â”€ merge_with_gemini()        # Merge with Gemini text
â”‚       â”‚   â”‚   â””â”€â”€ cleanup()                  # Free memory
â”‚       â”‚   â””â”€â”€ Features:
â”‚       â”‚       â€¢ Word-level timestamps (Â±50-200ms)
â”‚       â”‚       â€¢ Forced phoneme alignment
â”‚       â”‚       â€¢ Multiple model sizes (tiny to large-v3)
â”‚       â”‚
â”‚       â”œâ”€â”€ ðŸŽ­ pyannote_service.py        # Pyannote integration (250 lines)
â”‚       â”‚   â”œâ”€â”€ PyannoteService
â”‚       â”‚   â”‚   â”œâ”€â”€ diarize()                  # Speaker diarization
â”‚       â”‚   â”‚   â”œâ”€â”€ assign_speakers_to_segments()
â”‚       â”‚   â”‚   â”œâ”€â”€ get_speaker_embedding()    # Voice fingerprint
â”‚       â”‚   â”‚   â”œâ”€â”€ match_speakers_across_chunks()
â”‚       â”‚   â”‚   â”œâ”€â”€ relabel_speakers_human_friendly()
â”‚       â”‚   â”‚   â””â”€â”€ cleanup()
â”‚       â”‚   â””â”€â”€ Features:
â”‚       â”‚       â€¢ Voice biometric identification
â”‚       â”‚       â€¢ Neural speaker embeddings
â”‚       â”‚       â€¢ 85-95% accuracy
â”‚       â”‚       â€¢ Confidence scores
â”‚       â”‚
â”‚       â”œâ”€â”€ ðŸ§© chunk_stitcher.py          # Chunk management (230 lines)
â”‚       â”‚   â”œâ”€â”€ ChunkStitcher
â”‚       â”‚   â”‚   â”œâ”€â”€ stitch_chunks()            # Merge chunks
â”‚       â”‚   â”‚   â”œâ”€â”€ _build_speaker_mapping()   # Global speaker IDs
â”‚       â”‚   â”‚   â”œâ”€â”€ _match_speaker_across_chunks()
â”‚       â”‚   â”‚   â”œâ”€â”€ get_speaker_count()
â”‚       â”‚   â”‚   â”œâ”€â”€ get_speaker_timeline()     # When each speaker talks
â”‚       â”‚   â”‚   â””â”€â”€ get_speaker_statistics()   # Time, word count, %
â”‚       â”‚   â””â”€â”€ Features:
â”‚       â”‚       â€¢ Cross-chunk speaker consistency
â”‚       â”‚       â€¢ Boundary overlap analysis
â”‚       â”‚       â€¢ Global speaker ID mapping
â”‚       â”‚       â€¢ Speaker analytics
â”‚       â”‚
â”‚       â””â”€â”€ ðŸ”§ audio_preprocessor.py      # Audio preprocessing (200 lines)
â”‚           â”œâ”€â”€ AudioPreprocessor
â”‚           â”‚   â”œâ”€â”€ normalize_audio()          # Volume normalization
â”‚           â”‚   â”œâ”€â”€ reduce_noise()             # Spectral gating
â”‚           â”‚   â”œâ”€â”€ apply_high_pass_filter()   # Remove rumble
â”‚           â”‚   â”œâ”€â”€ remove_silence()           # Trim silence
â”‚           â”‚   â”œâ”€â”€ preprocess_full_pipeline() # All preprocessing
â”‚           â”‚   â”œâ”€â”€ convert_to_mono()
â”‚           â”‚   â”œâ”€â”€ resample()
â”‚           â”‚   â””â”€â”€ get_audio_info()
â”‚           â””â”€â”€ Features:
â”‚               â€¢ Noise reduction
â”‚               â€¢ Audio normalization
â”‚               â€¢ High-pass filtering
â”‚               â€¢ Silence removal
â”‚
â”œâ”€â”€ ðŸ“ components/                        # Original: React components
â”‚   â”œâ”€â”€ TranscriptCard.tsx
â”‚   â”œâ”€â”€ AudioVisualizer.tsx
â”‚   â”œâ”€â”€ FeedbackModal.tsx
â”‚   â”œâ”€â”€ GlossaryManager.tsx
â”‚   â”œâ”€â”€ ShortcutManager.tsx
â”‚   â”œâ”€â”€ SkeletonLoader.tsx
â”‚   â””â”€â”€ icons/
â”‚       â””â”€â”€ ... (icon components)
â”‚
â”œâ”€â”€ ðŸ“ utils/                             # Original: Utility functions
â”‚   â”œâ”€â”€ audio.ts
â”‚   â”œâ”€â”€ audioSlicer.ts
â”‚   â””â”€â”€ file.ts
â”‚
â”œâ”€â”€ ðŸŽ¨ App.tsx                            # Original: Main React component (1066 lines)
â”œâ”€â”€ ðŸŽ¨ index.tsx                          # Original: React entry point
â”œâ”€â”€ ðŸŽ¨ index.css                          # Original: Global styles
â””â”€â”€ ðŸ“„ metadata.json                      # Original: App metadata
```

## File Counts

| Category | Count | Total Lines |
|----------|-------|-------------|
| **Backend Python Files** | 6 | ~1,450 |
| **Frontend TypeScript Files** | 1 new | ~250 |
| **Documentation** | 4 | ~2,500 words |
| **Configuration** | 4 | - |
| **Scripts** | 3 | - |

## New Files Created (Option B)

### Backend Services (6 files)

1. **main.py** - FastAPI server with 2 API endpoints
2. **services/whisperx_service.py** - WhisperX timestamp alignment
3. **services/pyannote_service.py** - Pyannote speaker diarization
4. **services/chunk_stitcher.py** - Cross-chunk speaker mapping
5. **services/audio_preprocessor.py** - Audio preprocessing pipeline
6. **test_backend.py** - Setup verification and testing

### Frontend Integration (1 file)

7. **src/services/postprocessing.ts** - Backend API client

### Configuration (4 files)

8. **backend/requirements.txt** - Python dependencies
9. **backend/.env.example** - Backend environment template
10. **.env.example** - Frontend environment template (updated)
11. **backend/services/__init__.py** - Services package init

### Documentation (4 files)

12. **QUICKSTART.md** - 10-minute setup guide
13. **ENHANCED_ACCURACY_GUIDE.md** - Technical deep-dive (12 pages)
14. **backend/README.md** - Backend documentation (8 pages)
15. **IMPLEMENTATION_SUMMARY.md** - Implementation overview

### Setup Scripts (3 files)

16. **setup.sh** - Linux/Mac setup automation
17. **setup.bat** - Windows setup automation
18. **PROJECT_STRUCTURE.md** - This file

**Total: 18 new files**

## Technology Stack

### Frontend (Existing)

- **Framework**: React 19.2.0
- **Build Tool**: Vite 6.2.0
- **Language**: TypeScript 5.8.2
- **AI Service**: Google Generative AI (Gemini)
- **State Management**: React Hooks
- **Storage**: LocalStorage for persistence

### Backend (New)

- **Framework**: FastAPI 0.109.0
- **Language**: Python 3.9+
- **Web Server**: Uvicorn
- **Transcription**: WhisperX 3.1.1 (OpenAI Whisper base)
- **Speaker Diarization**: Pyannote.audio 3.1.1
- **Audio Processing**: Librosa 0.10.1, SoundFile
- **Deep Learning**: PyTorch 2.1.2
- **API Validation**: Pydantic 2.5.3

## Data Flow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. USER UPLOADS AUDIO                                   â”‚
â”‚    â””â”€> Frontend (React)                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 2. GEMINI TRANSCRIPTION                                 â”‚
â”‚    â””â”€> services/gemini.ts                               â”‚
â”‚    â””â”€> Result: Raw transcript with AI-inferred data    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 3. POST-PROCESSING REQUEST                              â”‚
â”‚    â””â”€> services/postprocessing.ts                       â”‚
â”‚    â””â”€> POST /enhance-transcript                        â”‚
â”‚        â€¢ Audio file                                     â”‚
â”‚        â€¢ Gemini transcript                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 4. BACKEND PROCESSING                                   â”‚
â”‚    â”œâ”€> audio_preprocessor.py (clean audio)             â”‚
â”‚    â”œâ”€> whisperx_service.py (accurate timestamps)       â”‚
â”‚    â”œâ”€> pyannote_service.py (speaker labels)            â”‚
â”‚    â””â”€> chunk_stitcher.py (merge chunks if needed)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 5. ENHANCED RESULT                                      â”‚
â”‚    â””â”€> JSON response with:                              â”‚
â”‚        â€¢ Word-level timestamps (Â±200ms)                 â”‚
â”‚        â€¢ Biometric speaker labels (85-95% accurate)     â”‚
â”‚        â€¢ Confidence scores                              â”‚
â”‚        â€¢ Processing metadata                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 6. DISPLAY TO USER                                      â”‚
â”‚    â””â”€> Frontend formats and displays enhanced transcriptâ”‚
â”‚    â””â”€> Export options: SRT, JSON, Text, Markdown       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## API Communication

### Frontend â†’ Backend

**Endpoint**: `POST http://localhost:8000/enhance-transcript`

**Request**:
```typescript
const formData = new FormData();
formData.append('audio_file', audioFile);
formData.append('gemini_transcript', rawTranscript);
formData.append('enable_timestamp_alignment', 'true');
formData.append('enable_speaker_verification', 'true');
formData.append('num_speakers', '2');
```

**Response**:
```json
{
  "segments": [
    {
      "text": "Welcome to the meeting",
      "start": 0.523,
      "end": 2.314,
      "speaker": "Speaker A",
      "words": [
        {"word": "Welcome", "start": 0.523, "end": 0.891, "score": 0.95}
      ]
    }
  ],
  "processing_info": {
    "timestamp_alignment": "completed",
    "speaker_verification": "completed",
    "word_count": 142,
    "speakers_detected": 2
  }
}
```

## Port Configuration

| Service | Default Port | Configuration |
|---------|-------------|---------------|
| Frontend (Vite) | 5173 | `vite.config.ts` |
| Backend (FastAPI) | 8000 | `backend/.env` â†’ `PORT` |

## Environment Variables

### Frontend (.env.local)

```env
API_KEY=your_gemini_api_key                    # Existing
VITE_BACKEND_URL=http://localhost:8000         # New
```

### Backend (backend/.env)

```env
HUGGINGFACE_TOKEN=hf_your_token_here           # New (required)
WHISPER_MODEL=medium                           # New (optional)
DEVICE=cpu                                     # New (optional)
CORS_ORIGINS=http://localhost:5173             # New (optional)
HOST=0.0.0.0                                   # New (optional)
PORT=8000                                      # New (optional)
```

## Dependency Sizes

### Frontend (npm packages)

- Total: ~500 MB (existing React/Vite dependencies)
- No new dependencies added

### Backend (pip packages)

| Package | Size | Purpose |
|---------|------|---------|
| torch | ~2.5 GB | Deep learning framework |
| whisperx | ~500 MB | Timestamp alignment |
| pyannote.audio | ~200 MB | Speaker diarization |
| librosa | ~100 MB | Audio processing |
| Other packages | ~200 MB | Supporting libraries |
| **Total** | **~3.5 GB** | Backend dependencies |

## Hardware Requirements

### Minimum (CPU only)

- 8 GB RAM
- 10 GB disk space
- Dual-core processor
- Processing time: ~5-10min for 30min audio

### Recommended (GPU)

- 16 GB RAM
- 20 GB disk space
- NVIDIA GPU with 4+ GB VRAM
- Processing time: ~2-3min for 30min audio

### Optimal (GPU)

- 32 GB RAM
- 50 GB disk space
- NVIDIA GPU with 8+ GB VRAM
- Processing time: ~1-2min for 30min audio

## Next Steps

1. **Setup**: Run `setup.sh` (Linux/Mac) or `setup.bat` (Windows)
2. **Configure**: Edit `.env.local` and `backend/.env`
3. **Test**: Run `python backend/test_backend.py`
4. **Start**: Launch both services
5. **Use**: Upload audio and enjoy enhanced transcription!

For detailed instructions, see [QUICKSTART.md](QUICKSTART.md).
